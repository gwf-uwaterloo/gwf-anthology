{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import xml.etree.ElementTree as et\n",
    "from lxml import etree\n",
    "import xml.dom.minidom as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the last csv file with the file extract_from_xml_to_csv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the authors and their institutions\n",
    "# Update the range according to the latest year\n",
    "paper_url='https://api.openalex.org/works/https://doi.org/{DOI}'\n",
    "author_url = \"https://api.openalex.org/authors/{ID}\"\n",
    "\n",
    "years = range(16,25)\n",
    "results = pd.DataFrame(columns=['doi','Name','Name_Variants','Institution'])\n",
    "author_ids = []\n",
    "\n",
    "# for doi in pd.read_csv(\"csv_all.csv\")[\"doi\"]:\n",
    "for year in years:\n",
    "    for doi in pd.read_csv(\"G\"+str(year)+\".csv\")[\"doi\"]:   \n",
    "        response = requests.get(url = paper_url.replace(\"{DOI}\", doi))\n",
    "        if response.status_code != 200:\n",
    "            print(\"not response\")\n",
    "            break\n",
    "        for author in response.json()['authorships']:\n",
    "            author_ids.append(author['author']['id'].replace(\"https://openalex.org/\",\"\"))\n",
    "            r = requests.get(url = author_url.replace(\"{ID}\", author['author']['id'].replace(\"https://openalex.org/\",\"\"))).json()\n",
    "            # names.append(r['display_name'])\n",
    "            # inst.append(r['last_known_institution']['display_name'])\n",
    "            results.loc[len(results.index)] = [doi, r['display_name'], r['display_name_alternatives'], r['last_known_institution']['display_name'] if r['last_known_institution'] else '']\n",
    "    # print(year)    \n",
    "    \n",
    "results.to_csv('author_detail.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the inst_code.csv file using new author_detail.csv file\n",
    "\n",
    "author_detail = pd.read_csv('author_detail.csv')\n",
    "sorted_institution = author_detail['Institution'].value_counts().index.to_list()\n",
    "\n",
    "#change the position of Uwaterloo and Usaskatchewan\n",
    "sorted_institution[0], sorted_institution[1] = sorted_institution[1], sorted_institution[0]\n",
    "\n",
    "#save\n",
    "pd.DataFrame({'Institution':sorted_institution, 'code':range(1, len(sorted_institution)+1)}).to_csv(\n",
    "    \"inst_code.csv\", \n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a code to all records in the author_detail.csv file \n",
    "author_detail = pd.read_csv('author_detail.csv')\n",
    "inst_code = pd.read_csv('inst_code.csv')\n",
    "\n",
    "author_detail['code'] = ['0000' if pd.isna(item) else '{:04d}'.format(inst_code[inst_code['Institution'] == item]['code'].item()) if item else '' for item in author_detail['Institution']]\n",
    "author_detail.to_csv('author_detail.csv', index=False)\n",
    "\n",
    "# manually edited in this step. removed duplicates ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update xml files with unified authors (name variants corrected)\n",
    "# replace the output files with the files in data/xml/ directory\n",
    "\n",
    "author_detail = pd.read_csv('author_detail.csv')\n",
    "xml_folder = '../data/xml/'\n",
    "years = range(2016,2025)\n",
    "\n",
    "for idx, year in enumerate(years):\n",
    "    tree = et.parse(xml_folder+\"G\"+str(year)[-2:]+\".xml\")\n",
    "    root = tree.getroot()\n",
    "    for paper in root.findall(\".//paper\"):\n",
    "        for author in paper.findall(\".//author\"):\n",
    "            paper.remove(author)\n",
    "\n",
    "        for author in author_detail[author_detail['doi'] == paper.find('.//doi').text]['Name'].iloc[::-1]:\n",
    "            first_name, last_name = author.rsplit(' ', 1) if len(author.split()) > 1 else (\"Md\", author)\n",
    "            element = et.Element(\"author\")            \n",
    "            tag_subelement = et.SubElement(element, \"first\")\n",
    "            tag_subelement.text = first_name\n",
    "            tag_subelement = et.SubElement(element, \"last\")\n",
    "            tag_subelement.text = last_name\n",
    "            paper.insert(1,element)\n",
    "            \n",
    "\n",
    "    tree = et.ElementTree(root)\n",
    "    file_name = \"G\"+str(year)[-2:]+\".xml\"   \n",
    "    with open(file_name, \"w\", encoding=\"UTF-8\") as f:\n",
    "        f.write(etree.tostring(etree.XML(et.tostring(root, encoding=\"UTF-8\", xml_declaration=True), parser=etree.XMLParser(remove_blank_text=True))).decode())\n",
    "\n",
    "    xml_pretty_str = md.parse(file_name)\n",
    "    xml_pretty_str = xml_pretty_str.toprettyxml(encoding='UTF-8').decode()\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(xml_pretty_str)  \n",
    "\n",
    "    # print(et.tostring(root, encoding='utf8').decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'canonical': {'first': 'Arash', 'last': 'Rafat'}, 'id': 'Arash-Rafat', 'comment': 'uni0006'}\n"
     ]
    }
   ],
   "source": [
    "# update name_variants.yaml\n",
    "# replace the output file with the file in data/yaml/ directory\n",
    "\n",
    "author_detail = pd.read_csv('author_detail.csv')\n",
    "\n",
    "dict_file = []\n",
    "\n",
    "for idx, item in author_detail[['Name', 'code']].drop_duplicates(subset=['Name'], keep='last').iterrows():\n",
    "    author = item['Name']\n",
    "    first_name, last_name = author.rsplit(' ', 1) if len(author.split()) > 1 else (\"Md\", author)\n",
    "    if author == 'Arash Rafat':\n",
    "        print({'canonical' : {'first': first_name, 'last': last_name}, \n",
    "               'id':first_name.replace('.', '')+'-'+last_name.replace('.', ''), \n",
    "               'comment':'uni{:04d}'.format(item['code'])})\n",
    "    dict_file.append({'canonical' : {'first': first_name, 'last': last_name}, \n",
    "                      'id':first_name.replace('.', '')+'-'+last_name.replace('.', ''), \n",
    "                      'comment':'uni{:04d}'.format(item['code'])})\n",
    "\n",
    "\n",
    "with open(r'name_variants.yaml', 'w') as file:\n",
    "    documents = yaml.dump(dict_file, file, default_flow_style=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{{ $universities := dict \"uni0001\" \"University of Saskatchewan\" \"uni0002\" \"University of Waterloo\" \"uni0003\" \"Global Institute for Water Security\" \"uni0004\" \"McMaster University\" \"uni0005\" \"Environment and Climate Change Canada\" \"uni0006\" \"Wilfrid Laurier University\" \"uni0007\" \"University of Calgary\" \"uni0008\" \"Université du Québec à Montréal\" \"uni0009\" \"University of Guelph\" \"uni0010\" \"Natural Resources Canada\" \"uni0011\" \"University of Manitoba\" \"uni0012\" \"University of Alberta\" \"uni0013\" \"National Center for Atmospheric Research\" \"uni0014\" \"Northern Arizona University\" \"uni0015\" \"Woodwell Climate Research Center\" \"uni0016\" \"Michigan State University\" \"uni0017\" \"University of British Columbia\" \"uni0018\" \"Universität Innsbruck\" \"uni0019\" \"Finnish Meteorological Institute\" \"uni0020\" \"Jet Propulsion Laboratory\" \"uni0021\" \"University of Alaska Fairbanks\" \"uni0022\" \"University of Toronto\" \"uni0023\" \"Czech University of Life Sciences Prague\" \"uni0024\" \"Swedish University of Agricultural Sciences\" \"uni0025\" \"Agriculture and Agri-Food Canada\" \"uni0026\" \"Lawrence Berkeley National Laboratory\" \"uni0027\" \"University of Ottawa\" \"uni0028\" \"University of Northern British Columbia\" \"uni0029\" \"University of California, Berkeley\" \"uni0030\" \"University of Colorado Boulder\" \"uni0031\" \"University of Arizona\" \"uni0032\" \"Max Planck Institute for Biogeochemistry\" \"uni0033\" \"Imperial College London\" \"uni0034\" \"Helmholtz Centre Potsdam - GFZ German Research Centre for Geosciences\" \"uni0035\" \"French National Centre for Scientific Research\" \"uni0036\" \"National Research Council\" \"uni0037\" \"Wageningen University & Research\" \"uni0038\" \"University of Helsinki\" \"uni0039\" \"Swiss Federal Institute for Forest, Snow and Landscape Research\" \"uni0040\" \"Pacific Institute for Climate Solutions\" \"uni0041\" \"ETH Zurich\" \"uni0042\" \"Aarhus University\" \"uni0043\" \"San Diego State University\" \"uni0044\" \"Pennsylvania State University\" \"uni0045\" \"Dalhousie University\" \"uni0046\" \"United States Geological Survey\" \"uni0047\" \"Center for Northern Studies\" \"uni0048\" \"Government of Northwest Territories\" \"uni0049\" \"Université de Montréal\" \"uni0050\" \"Xiamen University\"}}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# produce a line of code for 50 first universities\n",
    "# put it in the second line of hugo\\layouts\\index.html\n",
    "\n",
    "inst_code = pd.read_csv('inst_code.csv')\n",
    "\n",
    "out_str = '{{ $universities := dict'\n",
    "for idx, inst in inst_code.iloc[:50].iterrows():\n",
    "    out_str += ' \"'+'uni{:04d}'.format(inst['code'])+'\" \"'+inst['Institution']+'\"'    \n",
    "out_str += '}}' \n",
    "\n",
    "out_str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
